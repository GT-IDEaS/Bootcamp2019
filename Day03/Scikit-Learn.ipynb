{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Basics\n",
    "\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "\n",
    "### Tutorial and nice resources\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/index.html\n",
    "\n",
    "https://stackoverflow.com/\n",
    "\n",
    "\n",
    "### Nice sources for Datasets\n",
    "\n",
    "https://archive.ics.uci.edu/ml/index.php (datasets, datasets, all kinds of datasets)\n",
    "\n",
    "https://www.kaggle.com/ (earn some money while challenging your skill?)\n",
    "\n",
    "https://www.google.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Review\n",
    "\n",
    "### Types of machine learning problems?\n",
    "* \n",
    "* \n",
    "\n",
    "### Types of data?\n",
    "* \n",
    "* \n",
    "* \n",
    "* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step -1: apply your domain knowledge, understand the dataset and problem\n",
    "# learn about different models, choose the ones that make sense and try\n",
    "\n",
    "# step 0: load useful python libraries/packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle # used to save/load model\n",
    "from sklearn import some_model # load the model definition from scikit-learn\n",
    "\n",
    "# Prepare DATA (for both training and test)\n",
    "X_train = \n",
    "y_train = \n",
    "X_test = \n",
    "y_test = \n",
    "\n",
    "# The shape of X's should be (num_samples, num_feature)\n",
    "# The shape of y's should be (num_samples, 1) or (num_samples,)\n",
    "\n",
    "###############################################\n",
    "################ The ML part ##################\n",
    "###############################################\n",
    "# Initalize model\n",
    "model = some_model()\n",
    "\n",
    "# fit/train the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# test/predict with the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "some_error_metric(y_test, y_pred) # you need to define this error metric\n",
    "################################################\n",
    "\n",
    "\n",
    "\n",
    "# save model\n",
    "with open('my_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)    \n",
    "\n",
    "# load it again\n",
    "with open('my_model.pkl', 'rb') as f:\n",
    "    model_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metric: Mean Sqaured Error\n",
    "# $\\frac{1}{n} \\sum (y_{actual} - y_{pred})^2$\n",
    "\n",
    "### Error metric: Mean Absolute Percentage Error\n",
    "# $\\frac{1}{n} \\sum \\frac{|y_{actual} - y_{pred}|}{y_{actual}} \\times 100 \\%$\n",
    "\n",
    "### Visualization: Parity Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try it with a simple example\n",
    "fit $y = 3x^2 + 2x + 3$ in the interval x = [0, 100]\n",
    "\n",
    "with \n",
    "1. $x$\n",
    "2. $x$ and $x^2$\n",
    "\n",
    "use 101 evenly spaced data points as both training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Two Types of Error Metrics\n",
    "\n",
    "def mape(y,y_pred):\n",
    "    result = np.mean(np.abs(y-y_pred)/y)\n",
    "    print(\"The mape is {}%\".format(result*100))\n",
    "    return result\n",
    "\n",
    "def mse(y,y_pred):\n",
    "    result = np.mean((y-y_pred)**2)\n",
    "    print(\"The mse is {}\".format(result))\n",
    "    return result\n",
    "\n",
    "\n",
    "# Parity Plot\n",
    "\n",
    "def parity_plot(y,y_pred):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(y,y_pred )\n",
    "    plt.plot([min(y), max(y)],[min(y), max(y)], color='red')\n",
    "    plt.xlabel(\"y\")\n",
    "    plt.ylabel(\"predicted y\")\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "def plot(x,y,y_pred):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(x,y, color = \"red\", label = \"actual y\" )\n",
    "    plt.scatter(x,y_pred, color = \"blue\", label = \"predicted y\" )\n",
    "    \n",
    "    plt.xlabel(\"y\")\n",
    "    plt.ylabel(\"predicted y\")\n",
    "    plt.legend()\n",
    "    plt.show()  \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "\n",
    "X_train = np.linspace(0, 100, 101).reshape(101,1)\n",
    "y_train = 3 * X_train ** 2 + 2 * X_train + 3\n",
    "X_test = X_train\n",
    "y_test = y_train\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model for 1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "mse(y_test, y_predict)\n",
    "plot(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_2 = np.transpose([np.linspace(0, 100, 101), np.linspace(0, 100, 101) **2])\n",
    "X_test_2 = X_train_2\n",
    "\n",
    "print(X_train_2.shape)\n",
    "X_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model for 2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_2, y_train)\n",
    "y_predict = model.predict(X_test_2)\n",
    "\n",
    "mse(y_test, y_predict)\n",
    "plot(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save and reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "   \n",
    "\n",
    "# load it again\n",
    "\n",
    "\n",
    "# test loaded model\n",
    "y_predict = model_loaded.predict(X_test_2)\n",
    "mse(y_test, y_predict)\n",
    "plot(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Challenge\n",
    "\n",
    "This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "* id: a notation for a house\n",
    "* date: Date house was sold\n",
    "* price: Price is prediction TARGET!!\n",
    "* bedrooms: Number of Bedrooms/House\n",
    "* bathrooms: Number of bathrooms/House\n",
    "* sqft_living: square footage of the home\n",
    "* sqft_lot: square footage of the lot\n",
    "* floors: Total floors (levels) in house\n",
    "* waterfront: House which has a view to a waterfront\n",
    "* view: Has been viewed\n",
    "* condition: How good the condition is ( Overall )\n",
    "* grade: overall grade given to the housing unit, based on King County grading system\n",
    "* sqft_above: square footage of house apart from basement\n",
    "* sqft_basement: square footage of the basement\n",
    "* yr_built: Built Year\n",
    "* yr_renovated: Year when house was renovated\n",
    "* zip: codezip\n",
    "* lat: Latitude coordinate\n",
    "* long: Longitude coordinate\n",
    "* sqft_living15: Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area\n",
    "* sqft_lot15: lotSize area in 2015(implies-- some renovations)\n",
    "\n",
    "### Error metric: Mean Absolute Percentage Error\n",
    "# $\\frac{1}{n} \\sum \\frac{|y_{actual} - y_{pred}|}{y_{actual}} \\times 100 \\%$\n",
    "\n",
    "### my best: mape = 25.9%  (using first 10000 data points as training set, the rest as test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kc_house_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset preprocess and train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target\n",
    "price = np.array(data[\"price\"])\n",
    "\n",
    "# choose the columns to be used in prediction\n",
    "column_selection = []\n",
    "\n",
    "selected_feature = np.array(data[column_selection])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split\n",
    "\n",
    "selected_feature_train = selected_feature[:10000]\n",
    "price_train = price[:10000]\n",
    "selected_feature_test = selected_feature[10000:]\n",
    "price_test = price[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some regression\n",
    "Choose any models from here: https://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression with different parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on the training set?\n",
    "\n",
    "price_predict = model.predict(selected_feature_train)\n",
    "mape(price_train, price_predict)\n",
    "parity_plot(price_train, price_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multi-layer perceptron (a.k.a. neural network!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification \n",
    "\n",
    "Linear Discriminant Analysis\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_lda_qda.html#sphx-glr-auto-examples-classification-plot-lda-qda-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Generate datasets\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Colormap\n",
    "cmap = colors.LinearSegmentedColormap(\n",
    "    'red_blue_classes',\n",
    "    {'red': [(0, 1, 1), (1, 0.7, 0.7)],\n",
    "     'green': [(0, 0.7, 0.7), (1, 0.7, 0.7)],\n",
    "     'blue': [(0, 0.7, 0.7), (1, 1, 1)]})\n",
    "plt.cm.register_cmap(cmap=cmap)\n",
    "\n",
    "\n",
    "def dataset_fixed_cov():\n",
    "    '''Generate 2 Gaussians samples with the same covariance matrix'''\n",
    "    n, dim = 300, 2\n",
    "    np.random.seed(0)\n",
    "    C = np.array([[0., -0.23], [0.83, .23]])\n",
    "    X = np.r_[np.dot(np.random.randn(n, dim), C),\n",
    "              np.dot(np.random.randn(n, dim), C) + np.array([1, 1])]\n",
    "    y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def dataset_cov():\n",
    "    '''Generate 2 Gaussians samples with different covariance matrices'''\n",
    "    n, dim = 300, 2\n",
    "    np.random.seed(0)\n",
    "    C = np.array([[0., -1.], [2.5, .7]]) * 2.\n",
    "    X = np.r_[np.dot(np.random.randn(n, dim), C),\n",
    "              np.dot(np.random.randn(n, dim), C.T) + np.array([1, 4])]\n",
    "    y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(y,y_pred):\n",
    "    result = (y == y_pred).sum() / len(y)\n",
    "    print(\"The classification accuracy is {}\".format(result))\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_data(X,y):\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    plt.figure(figsize=(10,10))\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_result(model,X,y):\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = dataset_fixed_cov()\n",
    "plot_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA classification\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X, y)\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "classification_accuracy(y,y_predict)\n",
    "plot_result(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different dataset\n",
    "X,y = dataset_cov()\n",
    "plot_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with the Iris Dataset\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n",
    "\n",
    "Predicted attribute: class of iris plant. \n",
    "\n",
    "This is an exceedingly simple domain. \n",
    "\n",
    "This data differs from the data presented in Fishers article (identified by Steve Chadwick, spchadwick '@' espeedaz.net ). The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "3. petal length in cm \n",
    "4. petal width in cm \n",
    "5. class: \n",
    "-- Iris Setosa \n",
    "-- Iris Versicolour \n",
    "-- Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, :2], iris.target\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
