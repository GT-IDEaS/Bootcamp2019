{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python for Ecologists: Working with Data using the `pandas` Library\n",
    "======================================================\n",
    "\n",
    "This exercise was adapted for our bootcamp from [this lesson](https://datacarpentry.org/python-ecology-lesson/) of the [Data Carpentry](https://datacarpentry.org/) series of workshops.  In this lesson, we will be exploring the [`pandas`](https://pandas.pydata.org/) library for data analysis, by working with a set of ecological data recorded in the Chihuahua desert in Arizona.  Please follow along with this activity by filling in the code cells while we go through this notebook together.\n",
    "\n",
    "# Working With Pandas DataFrames in Python\n",
    "\n",
    "We can automate the process of performing data manipulations in Python. It's efficient to spend time\n",
    "building the code to perform these tasks because once it's built, we can use it\n",
    "over and over on different datasets that use a similar format. This makes our\n",
    "methods easily reproducible. We can also easily share our code with colleagues\n",
    "and they can replicate the same analysis.\n",
    "\n",
    "### Our Data\n",
    "\n",
    "For this lesson, we will be using the Portal Teaching data, a subset of the data\n",
    "from Ernst _et al._\n",
    "Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal,\n",
    "Arizona, USA.\n",
    "\n",
    "This lesson will use the `surveys.csv` file included in the `data/` directory.\n",
    "\n",
    "We are studying the species and weight of animals caught in sites in our study\n",
    "area. The dataset is stored as a `.csv` file: each row holds information for a\n",
    "single animal, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| record_id        | Unique id for the observation      |\n",
    "| month            | month of observation               |\n",
    "| day              | day of observation                 |\n",
    "| year             | year of observation                |\n",
    "| plot_id          | ID of a particular site            |\n",
    "| species_id       | 2-letter code                      |\n",
    "| sex              | sex of animal (\"M\", \"F\")           |\n",
    "| hindfoot_length  | length of the hindfoot in mm       |\n",
    "| weight           | weight of the animal in grams      |\n",
    "\n",
    "\n",
    "The first few rows of our first file look like this:\n",
    "\n",
    "~~~\n",
    "record_id,month,day,year,plot_id,species_id,sex,hindfoot_length,weight\n",
    "1,7,16,1977,2,NL,M,32,\n",
    "2,7,16,1977,3,NL,M,33,\n",
    "3,7,16,1977,2,DM,F,37,\n",
    "4,7,16,1977,7,DM,M,36,\n",
    "5,7,16,1977,3,DM,M,35,\n",
    "6,7,16,1977,1,PF,M,14,\n",
    "7,7,16,1977,2,PE,F,,\n",
    "8,7,16,1977,1,DM,M,37,\n",
    "9,7,16,1977,1,DM,F,34,\n",
    "~~~\n",
    "\n",
    "## About Libraries\n",
    "A library in Python contains a set of tools (called functions) that perform\n",
    "tasks on our data. Importing a library is like getting a piece of lab equipment\n",
    "out of a storage locker and setting it up on the bench for use in a project.\n",
    "Once a library is set up, it can be used or called to perform many tasks.\n",
    "\n",
    "## Pandas in Python\n",
    "One of the best options for working with tabular data in Python is to use the\n",
    "[Python Data Analysis Library][pandas] (a.k.a. Pandas). The\n",
    "Pandas library provides data structures, produces high quality plots with\n",
    "[matplotlib][matplotlib] and integrates nicely with other libraries\n",
    "that use [NumPy][numpy] (which is another Python library) arrays.\n",
    "\n",
    "Python doesn't load all of the libraries available to it by default. We have to\n",
    "add an `import` statement to our code in order to use library functions. To import\n",
    "a library, we use the syntax `import libraryName`. If we want to give the\n",
    "library a nickname to shorten the command, we can add `as nickNameHere`.  An\n",
    "example of importing the pandas library using the common nickname `pd` is below:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "In the cell below, please import `pandas` with the appropriate abbreviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library on the next line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we call a function that's in a library, we use the syntax\n",
    "`LibraryName.FunctionName`. Adding the library name with a `.` before the\n",
    "function name tells Python where to find the function. In the example above, we\n",
    "have imported Pandas as `pd`. This means we don't have to type out `pandas` each\n",
    "time we call a Pandas function.\n",
    "\n",
    "\n",
    "## Reading CSV Data Using Pandas\n",
    "\n",
    "We will begin by locating and reading our survey data which are in CSV format. CSV stands for\n",
    "Comma-Separated Values and is a common way store formatted data. Other symbols may also be used, so\n",
    "you might see tab-separated, colon-separated or space separated files. It is quite easy to replace\n",
    "one separator with another, to match your application. The first line in the file often has headers\n",
    "to explain what is in each column. CSV (and other separators) make it easy to share data, and can be\n",
    "imported and exported from many applications, including Microsoft Excel.\n",
    "We can use Pandas' `read_csv` function to pull the file directly into a \n",
    "[`pd.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were 35,549 rows parsed. Each row has 9\n",
    "columns. The first column is the index of the DataFrame. The index is used to\n",
    "identify the position of the data, but it is not an actual column of the DataFrame.\n",
    "It looks like  the `read_csv` function in Pandas  read our file properly. However,\n",
    "we haven't saved any data to memory so we can work with it. We need to assign the\n",
    "DataFrame to a variable. Remember that a variable is a name for a value, such as `x`,\n",
    "or  `data`. We can create a new  object with a variable name by assigning a value to it using `=`.\n",
    "\n",
    "Let's call the imported survey data `surveys_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from `surveys.csv` into a variable\n",
    "surveys_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice when you assign the imported DataFrame to a variable, Python does not\n",
    "produce any output on the screen. We can view the value of the `surveys_df`\n",
    "object by typing its name into the Python command prompt, which prints contents like above.\n",
    "\n",
    "Note: if the output is too wide to print on your narrow terminal window, you may see something\n",
    "slightly different as the large set of data scrolls past. You may see simply the last column\n",
    "of data:\n",
    "```\n",
    "17        NaN\n",
    "18        NaN\n",
    "19        NaN\n",
    "20        NaN\n",
    "21        NaN\n",
    "22        NaN\n",
    "23        NaN\n",
    "24        NaN\n",
    "...       ...\n",
    "35543     NaN\n",
    "35544     NaN\n",
    "35545     NaN\n",
    "35546    14.0\n",
    "35547    51.0\n",
    "35548     NaN\n",
    "\n",
    "[35549 rows x 9 columns]\n",
    "```\n",
    "Never fear, all the data is there, if you scroll up. Selecting just a few rows, so it is\n",
    "easier to fit on one window, you can see that pandas has neatly formatted the data to fit\n",
    "our screen:\n",
    "```\n",
    ">>> surveys_df.head() # The head() method displays the first several lines of a file. It\n",
    "                      # is discussed below.\n",
    "                  \n",
    "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
    "5          6      7   16  1977        1         PF   M             14.0\n",
    "6          7      7   16  1977        2         PE   F              NaN\n",
    "7          8      7   16  1977        1         DM   M             37.0\n",
    "8          9      7   16  1977        1         DM   F             34.0\n",
    "9         10      7   16  1977        6         PF   F             20.0\n",
    "\n",
    "   weight\n",
    "5     NaN\n",
    "6     NaN\n",
    "7     NaN\n",
    "8     NaN\n",
    "9     NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Our Species Survey Data\n",
    "\n",
    "Again, we can use the `type` function to see what kind of thing `surveys_df` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Python built-in function type()\n",
    "\n",
    "\n",
    "# this does the same thing as the above!\n",
    "# surveys_df.__class__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it's a DataFrame (or, to use the full name that Python uses to refer\n",
    "to it internally, a `pandas.core.frame.DataFrame`).\n",
    "\n",
    "What kind of things does `surveys_df` contain? DataFrames have an attribute\n",
    "called `dtypes` that answers this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the surveys_df `dtypes` attribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values in a column have the same type. For example, months have type\n",
    "`int64`, which is a kind of integer. Cells in the month column cannot have\n",
    "fractional values, but the weight and hindfoot_length columns can, because they\n",
    "have type `float64`. The `object` type doesn't have a very helpful name, but in\n",
    "this case it represents strings (such as 'M' and 'F' in the case of sex).\n",
    "\n",
    "We'll talk a bit more about what the different formats mean in a different lesson.\n",
    "\n",
    "### Useful Ways to View DataFrame objects in Python\n",
    "\n",
    "There are many ways to summarize and access the data stored in DataFrames,\n",
    "using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "To access an attribute, use the DataFrame object name followed by the attribute\n",
    "name `df_object.attribute`. Using the DataFrame `surveys_df` and attribute\n",
    "`columns`, an index of all the column names in the DataFrame can be accessed\n",
    "with `surveys_df.columns`.\n",
    "\n",
    "Methods are called in a similar fashion using the syntax `df_object.method()`.\n",
    "As an example, `surveys_df.head()` gets the first few rows in the DataFrame\n",
    "`surveys_df` using **the `head()` method**. With a method, we can supply extra\n",
    "information in the parens to control behaviour.\n",
    "\n",
    "Let's look at the data using these.\n",
    "\n",
    "---\n",
    "\n",
    "### Challenge: DataFrames\n",
    "\n",
    "> Using our DataFrame `surveys_df`, try out the attributes & methods below to see\n",
    "> what they return.\n",
    ">\n",
    "> 1. `surveys_df.columns`\n",
    "> 2. `surveys_df.shape` Take note of the output of `shape` - what format does it\n",
    ">    return the shape of the DataFrame in?\n",
    ">\n",
    ">    HINT: [More on tuples, here][python-datastructures].\n",
    "> 3. `surveys_df.head()` Also, what does `surveys_df.head(15)` do?\n",
    "> 4. `surveys_df.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in code for DataFrames Challenge here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Statistics From Data In A Pandas DataFrame\n",
    "\n",
    "We've read our data into Python. Next, let's perform some quick summary\n",
    "statistics to learn more about the data that we're working with. We might want\n",
    "to know how many animals were collected in each site, or how many of each\n",
    "species were caught. We can perform summary stats quickly using groups. But\n",
    "first we need to figure out what we want to group by.\n",
    "\n",
    "Let's begin by exploring our data. Let's get a list of all the species. The `pd.unique` \n",
    "function tells us all of the unique values in the `species_id` column. We can examine\n",
    "a single column of the dataframe by indexing by the name of the column of interest:\n",
    "```python\n",
    "surveys_df['species_id']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call pd.unique() on column of dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Statistics\n",
    ">\n",
    "> 1. Create a list of unique site ID's (\"plot_id\") found in the surveys data. Call it\n",
    ">   `site_names`. How many unique sites are there in the data? How many unique\n",
    ">   species are in the data?\n",
    ">\n",
    "> 2. What is the difference between `len(site_names)` and `surveys_df['plot_id'].nunique()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Statistics Challenge here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups in Pandas\n",
    "\n",
    "We often want to calculate summary statistics grouped by subsets or attributes\n",
    "within fields of our data. For example, we might want to calculate the average\n",
    "weight of all individuals per site.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the\n",
    "`describe()` method with syntax\n",
    "```python\n",
    "df['column'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the \"weight\" column of our survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary statistics for the \"weight\" column:\n",
    "weight_min =                               # Minimum\n",
    "weight_max =                               # Maximum\n",
    "weight_mean =                              # Mean\n",
    "weight_std =                               # Standard Deviation\n",
    "weight_count =                             # Count of entries in column\n",
    "\n",
    "print(f'Minimum weight: {weight_min}')\n",
    "print(f'Maximum weight: {weight_max}')\n",
    "print(f'Mean weight: {weight_mean}')\n",
    "print(f'Standard Deviation of weight: {weight_std}')\n",
    "print(f'Count of entries in weight column: {weight_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to summarize by one or more variables, for example sex, we can\n",
    "use **Pandas' `.groupby` method**. Once we've created a groupby DataFrame, we\n",
    "can quickly calculate summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sex\n",
    "grouped_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **pandas function `describe`** will return descriptive stats including: mean,\n",
    "median, max, min, std and count for a particular column in the data. Pandas'\n",
    "`describe` function will only return summary values for columns containing\n",
    "numeric data. In the cell below, describe the data grouped by sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics for all numeric columns by sex\n",
    "\n",
    "\n",
    "# provide the mean for each numeric column by sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby` command is powerful in that it allows us to quickly generate\n",
    "summary stats.\n",
    "\n",
    "### Challenge: Summary Data\n",
    ">\n",
    "> 1. How many recorded individuals are female `F` and how many male `M`\n",
    "> 2. What happens when you group by two columns using the following syntax and\n",
    ">    then grab mean values:\n",
    ">   - `grouped_data2 = surveys_df.groupby(['plot_id','sex'])`\n",
    ">   - `grouped_data2.mean()`\n",
    "> 3. Summarize weight values for each site in your data. HINT: you can use the\n",
    ">   following syntax to only create summary statistics for one column in your data\n",
    ">   `by_site['weight'].describe()`\n",
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for the Summary Data challenge below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Did you get #3 right?\n",
    "> **A Snippet of the Output from challenge 3 looks like:**\n",
    ">\n",
    "> ~~~\n",
    ">  site\n",
    ">  1     count    1903.000000\n",
    ">        mean       51.822911\n",
    ">        std        38.176670\n",
    ">        min         4.000000\n",
    ">        25%        30.000000\n",
    ">        50%        44.000000\n",
    ">        75%        53.000000\n",
    ">        max       231.000000\n",
    ">          ...\n",
    "> ~~~\n",
    "\n",
    "## Quickly Creating Summary Counts in Pandas\n",
    "\n",
    "Let's next count the number of samples for each species. We can do this in a few\n",
    "ways, but we'll use `groupby` combined with **a `count()` method**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count the number of samples by species\n",
    "species_counts = \n",
    "print(species_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can also count just the rows that have the species \"DO\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Make a list\n",
    ">\n",
    ">  What's another way to create a list of species and associated `count` of the\n",
    ">  records in the data? Hint: you can perform `count`, `min`, etc functions on\n",
    ">  groupby DataFrames in the same way you can perform them on regular DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for your List challenge problem below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Math Functions\n",
    "\n",
    "If we wanted to, we could perform math on an entire column of our data. For\n",
    "example let's multiply all weight values by 2. A more practical use of this might\n",
    "be to normalize the data according to a mean, area, or some other value\n",
    "calculated from our data.  For example, to multiply all entries in the `\"weight\"`\n",
    "column by 2:\n",
    "```python\n",
    "surveys_df['weight']*2\n",
    "```\n",
    "\n",
    "## Quick & Easy Plotting Data Using Pandas\n",
    "\n",
    "We can plot our summary stats using Pandas, too.  To get our figures to appear directly\n",
    "in this Jupyter notebook, we can use the Magic `%matplotlib inline` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Jupyter magic to make figures appear inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a quick bar chart of the number of species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a quick bar chart\n",
    "species_counts.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at how many animals were captured in each site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by plot_id, and return the number of unique record ID's\n",
    "total_count = \n",
    "# let's plot that too\n",
    "total_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Plots\n",
    ">\n",
    "> 1. Create a plot of average weight across all species per site.\n",
    "> 2. Create a plot of total males versus total females for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting challenge code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Plotting Challenge\n",
    ">\n",
    "> Create a stacked bar plot, with weight on the Y axis, and the stacked variable\n",
    "> being sex. The plot should show total weight by sex for each site. Some\n",
    "> tips are below to help you solve this challenge:\n",
    ">\n",
    "> * You can use the code that follows to create a stacked bar plot but the data to stack\n",
    ">  need to be in individual columns.  Here's a simple example with some data where\n",
    ">  'a', 'b', and 'c' are the groups, and 'one' and 'two' are the subgroups.\n",
    ">\n",
    "> ```python\n",
    "> d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "> pd.DataFrame(d)\n",
    "> ```\n",
    ">\n",
    "> shows the following data\n",
    ">\n",
    "> ```\n",
    ">       one  two\n",
    ">   a    1    1\n",
    ">   b    2    2\n",
    ">   c    3    3\n",
    ">   d  NaN    4\n",
    "> ```\n",
    ">\n",
    "> We can plot the above with\n",
    ">\n",
    "> ```\n",
    "> # Plot stacked data so columns 'one' and 'two' are stacked\n",
    "> my_df = pd.DataFrame(d)\n",
    "> my_df.plot(kind='bar',stacked=True,title=\"The title of my graph\")\n",
    "> ```\n",
    ">\n",
    "> * You can use the `.unstack()` method to transform grouped data into columns\n",
    "> for each plotting.  Try running `.unstack()` on some DataFrames above and see\n",
    "> what it yields.\n",
    ">\n",
    "> Start by transforming the grouped data (by site and sex) into an unstacked layout, then create\n",
    "> a stacked plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing, Slicing and Subsetting DataFrames in Python\n",
    "\n",
    "## Indexing and Slicing in Python\n",
    "\n",
    "We often want to work with subsets of a **DataFrame** object. There are\n",
    "different ways to accomplish this including: using labels (column headings),\n",
    "numeric ranges, or specific x,y index locations.\n",
    "\n",
    "\n",
    "## Selecting data using Labels (Column Headings)\n",
    "\n",
    "We use square brackets `[]` to select a subset of a Python object. For example,\n",
    "we can select all data from a column named `species_id` from the `surveys_df`\n",
    "DataFrame by name. There are two ways to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP: use the .head() method we saw earlier to make output shorter\n",
    "# Method 1: select a 'subset' of the data using the column name\n",
    "surveys_df['species_id']\n",
    "\n",
    "# Method 2: use the column name as an 'attribute'; gives the same output\n",
    "surveys_df.species_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's store the `'species_id'` subset of the survey data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an object, surveys_species, that only contains the `species_id` column\n",
    "surveys_species = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a list of column names too, as an index to select columns in that\n",
    "order. This is useful when we need to reorganize our data.\n",
    "\n",
    "**NOTE:** If a column name is not contained in the DataFrame, an exception\n",
    "(error) will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the species and plot columns from the DataFrame\n",
    "surveys_df[['species_id', 'plot_id']]\n",
    "\n",
    "# what happens when you flip the order?\n",
    "#surveys_df[['plot_id', 'species_id']]\n",
    "\n",
    "#what happens if you ask for a column that doesn't exist?\n",
    "#surveys_df['speciess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Range based Subsets: Slicing\n",
    "\n",
    "> ## Reminder\n",
    "> Python uses 0-based indexing.\n",
    "\n",
    "### Slicing Subsets of Rows in Python\n",
    "\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a\n",
    "DataFrame. To slice out a set of rows, you use the following syntax:\n",
    "`data[start:stop]`. When slicing in pandas the start bound is included in the\n",
    "output. The stop bound is one step BEYOND the row you want to select. So if you\n",
    "want to select rows 0, 1 and 2 your code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows 0, 1, 2 (row 3 is not selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select the first 5 rows (rows 0, 1, 2, 3, 4)\n",
    "\n",
    "\n",
    "# select the last element in the list\n",
    "# (the slice starts at the last element,\n",
    "# and ends at the end of the list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reassign values within subsets of our DataFrame.\n",
    "\n",
    "But before we do that, let's look at the difference between the concept of\n",
    "copying objects and the concept of referencing objects in Python.\n",
    "\n",
    "## Copying Objects vs Referencing Objects in Python\n",
    "\n",
    "Let's start with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 'copy() method'\n",
    "true_copy_surveys_df = surveys_df.copy()\n",
    "\n",
    "# Using the '=' operator\n",
    "ref_surveys_df = surveys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might think that the code `ref_surveys_df = surveys_df` creates a fresh\n",
    "distinct copy of the `surveys_df` DataFrame object. However, using the `=`\n",
    "operator in the simple statement `y = x` does **not** create a copy of our\n",
    "DataFrame. Instead, `y = x` creates a new variable `y` that references the\n",
    "**same** object that `x` refers to. To state this another way, there is only\n",
    "**one** object (the DataFrame), and both `x` and `y` refer to it.\n",
    "\n",
    "In contrast, the `copy()` method for a DataFrame creates a true copy of the\n",
    "DataFrame.\n",
    "\n",
    "Let's look at what happens when we reassign the values within a subset of the\n",
    "DataFrame that references another DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the value `0` to the first three rows of data in the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the differences between referencing and copying objects! First, let's compare\n",
    "the result of our above efforts to set the first three rows of `ref_surveys_df` to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_surveys_df was created using the '=' operator\n",
    "ref_surveys_df.head()\n",
    "\n",
    "# surveys_df is the original dataframe\n",
    "#surveys_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between these two dataframes?\n",
    "\n",
    "When we assigned the first 3 columns the value of `0` using the\n",
    "`ref_surveys_df` DataFrame, the `surveys_df` DataFrame is modified too.\n",
    "Remember we created the reference `ref_survey_df` object above when we did\n",
    "`ref_survey_df = surveys_df`. Remember `surveys_df` and `ref_surveys_df`\n",
    "refer to the same exact DataFrame object. If either one changes the object,\n",
    "the other will see the same changes to the reference object.\n",
    "\n",
    "**To review and recap**:\n",
    "\n",
    "- **Copy** uses the dataframe's `copy()` method\n",
    "\n",
    "  ```\n",
    "  true_copy_surveys_df = surveys_df.copy()\n",
    "  ```\n",
    "- A **Reference** is created using the `=` operator\n",
    "\n",
    "  ```\n",
    "  ref_surveys_df = surveys_df\n",
    "  ```\n",
    "Okay, that's enough of that.  Let's reload a clean copy of our survey data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv('data/surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns in Python\n",
    "\n",
    "We can select specific ranges of our data in both the row and column directions\n",
    "using either label or integer-based indexing.\n",
    "\n",
    "- `loc` is primarily *label* based indexing. *Integers* may be used but\n",
    "  they are interpreted as a *label*.\n",
    "- `iloc` is primarily *integer* based indexing\n",
    "\n",
    "To select a subset of rows **and** columns from our DataFrame, we can use the\n",
    "`iloc` method. For example, we can select month, day and year (columns 2, 3\n",
    "and 4 if we start counting at 1), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n",
    "surveys_df.iloc[0:3, 1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for a slice from 0:3. This yielded 3 rows of data. When you\n",
    "ask for 0:3, you are actually telling Python to start at index 0 and select rows\n",
    "0, 1, 2 **up to but not including 3**.\n",
    "\n",
    "Let's explore some other ways to index and select subsets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns for rows of index values 0 and 10\n",
    "\n",
    "\n",
    "# what does this do?\n",
    "#surveys_df.loc[0, ['species_id', 'plot_id', 'weight']]\n",
    "\n",
    "# What happens when you type the code below?\n",
    "#surveys_df.loc[[0, 10, 35549], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Labels must be found in the DataFrame or you will get a `KeyError`.\n",
    "\n",
    "Indexing by labels `loc` differs from indexing by integers `iloc`.\n",
    "With `loc`, both the start bound and the stop bound are **inclusive**. When using\n",
    "`loc`, integers *can* be used, but the integers refer to the\n",
    "index label and not the position. For example, using `loc` and select 1:4\n",
    "will get a different result than using `iloc` to select rows 1:4.\n",
    "\n",
    "We can also select a specific data value using a row and\n",
    "column location within the DataFrame and `iloc` indexing:\n",
    "\n",
    "```\n",
    "# Syntax for iloc indexing to finding a specific data element\n",
    "dat.iloc[row, column]\n",
    "```\n",
    "In this `iloc` example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.iloc[2, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that Python indexing begins at 0. So, the index location [2, 6]\n",
    "selects the element that is 3 rows down and 7 columns over in the DataFrame.\n",
    "\n",
    "### Challenge: Range\n",
    ">\n",
    "> 1. What happens when you execute:\n",
    ">\n",
    ">    - `surveys_df[0:1]`\n",
    ">    - `surveys_df[:4]`\n",
    ">    - `surveys_df[:-1]`\n",
    ">\n",
    "> 2. What happens when you call:\n",
    ">\n",
    ">    - `surveys_df.iloc[0:4, 1:4]`\n",
    ">    - `surveys_df.loc[0:4, 1:4]`\n",
    ">\n",
    "> - How are the two commands different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range challenge code below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data using Criteria\n",
    "\n",
    "We can also select a subset of our data using criteria. For example, we can\n",
    "select all rows that have a year value of 2002:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boolean: Year matches 2002\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select all rows that do not contain the year 2002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boolean: Year matches 2002\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define sets of criteria too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Returns subset of rows with year in range 1980-1985 (inclusive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Syntax Cheat Sheet\n",
    "\n",
    "We can use the syntax below when querying data by criteria from a DataFrame.\n",
    "Experiment with selecting various subsets of the \"surveys\" data.\n",
    "\n",
    "* Equals: `==`\n",
    "* Not equals: `!=`\n",
    "* Greater than, less than: `>` or `<`\n",
    "* Greater than or equal to `>=`\n",
    "* Less than or equal to `<=`\n",
    "\n",
    "\n",
    "### Challenge: Queries\n",
    ">\n",
    "> 1. Select a subset of rows in the `surveys_df` DataFrame that contain data from\n",
    ">   the year 1999 and that contain weight values less than or equal to 8. How\n",
    ">   many rows did you end up with? What did your neighbor get?\n",
    ">\n",
    "> 2. You can use the `isin` command in Python to query a DataFrame based upon a\n",
    ">   list of values as follows:\n",
    ">\n",
    ">    ```python\n",
    ">    surveys_df[surveys_df['species_id'].isin([listGoesHere])]\n",
    ">    ```\n",
    ">\n",
    ">   Use the `isin` function to find all plots that contain particular species\n",
    ">   in the \"surveys\" DataFrame. How many records contain these values?\n",
    ">\n",
    "> 3. Experiment with other queries. Create a query that finds all rows with a\n",
    ">   weight value > or equal to 0.\n",
    ">\n",
    "> 4. The `~` symbol in Python can be used to return the OPPOSITE of the\n",
    ">   selection that you specify in Python. It is equivalent to **is not in**.\n",
    ">   Write a query that selects all rows with sex NOT equal to 'M' or 'F' in\n",
    ">   the \"surveys\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries challenge code below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using masks to identify a specific condition\n",
    "\n",
    "A **mask** can be useful to locate where a particular subset of values exist or\n",
    "don't exist - for example,  NaN, or \"Not a Number\" values. To understand masks,\n",
    "we also need to understand `BOOLEAN` objects in Python.\n",
    "\n",
    "Boolean values include `True` or `False`. For example,\n",
    "\n",
    "```python\n",
    "# Set x to 5\n",
    "x = 5\n",
    "\n",
    "# What does the code below return?\n",
    "x > 5\n",
    "\n",
    "# How about this?\n",
    "x == 5\n",
    "```\n",
    "\n",
    "When we ask Python whether `x` is greater than 5, it returns `False`.\n",
    "This is Python's way to say \"No\". Indeed, the value of `x` is 5,\n",
    "and 5 is not greater than 5.\n",
    "\n",
    "To create a boolean mask:\n",
    "\n",
    "- Set the True / False criteria (e.g. `values > 5 = True`)\n",
    "- Python will then assess each value in the object to determine whether the\n",
    "  value meets the criteria (True) or not (False).\n",
    "- Python creates an output object that is the same shape as the original\n",
    "  object, but with a `True` or `False` value for each index location.\n",
    "\n",
    "Let's try this out. Let's identify all locations in the survey data that have\n",
    "null (missing or NaN) data values. We can use the `isnull` method to do this.\n",
    "The `isnull` method will compare each cell with a null value. If an element\n",
    "has a null value, it will be assigned a value of  `True` in the output object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query a Boolean mask for null values in survey data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the rows where there are null values, we can use\n",
    "the mask as an index to subset our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To select just the rows with NaN values, we can use the 'any()' method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `weight` column of our DataFrame contains many `null` or `NaN`\n",
    "values. We will explore ways of dealing with this below.\n",
    "\n",
    "We can run `isnull` on a particular column too. What does the code below do?\n",
    "\n",
    "```python\n",
    "# What does this do?\n",
    "empty_weights = surveys_df[pd.isnull(surveys_df['weight'])]['weight']\n",
    "print(empty_weights)\n",
    "```\n",
    "\n",
    "Let's take a minute to look at the statement above. We are using the Boolean\n",
    "object `pd.isnull(surveys_df['weight'])` as an index to `surveys_df`. We are\n",
    "asking Python to select rows that have a `NaN` value of weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - Putting it all together\n",
    ">\n",
    "> 1. Create a new DataFrame that only contains observations with sex values that\n",
    ">   are **not** female or male. Assign each sex value in the new DataFrame to a\n",
    ">   new value of 'x'. Determine the number of null values in the subset.\n",
    ">\n",
    "> 2. Create a new DataFrame that contains only observations that are of sex male\n",
    ">   or female and where weight values are greater than 0. Create a stacked bar\n",
    ">   plot of average weight by plot with male vs female values stacked for each\n",
    ">   plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types and Formats\n",
    "The format of individual columns and rows will impact analysis performed on a\n",
    "dataset read into python. For example, you can't perform mathematical\n",
    "calculations on a string (text formatted data). This might seem obvious,\n",
    "however sometimes numeric values are read into Python as strings. In this\n",
    "situation, when you then try to perform calculations on the string-formatted\n",
    "numeric data, you get an error.\n",
    "\n",
    "In this lesson we will review ways to explore and better understand the\n",
    "structure and format of our data.\n",
    "\n",
    "## Types of Data\n",
    "\n",
    "How information is stored in a\n",
    "DataFrame or a Python object affects what we can do with it and the outputs of\n",
    "calculations as well. There are two main types of data that we're explore in\n",
    "this lesson: numeric and text data types.\n",
    "\n",
    "### Numeric Data Types\n",
    "\n",
    "Numeric data types include integers and floats. A **floating point** (known as a\n",
    "float) number has decimal points even if that decimal point value is 0. For\n",
    "example: 1.13, 2.0, 1234.345. If we have a column that contains both integers and\n",
    "floating point numbers, Pandas will assign the entire column to the float data\n",
    "type so the decimal points are not lost.\n",
    "\n",
    "An **integer** will never have a decimal point. Thus if we wanted to store 1.13 as\n",
    "an integer it would be stored as 1. Similarly, 1234.345 would be stored as 1234. You\n",
    "will often see the data type `Int64` in Python which stands for 64 bit integer. The 64\n",
    "simply refers to the memory allocated to store data in each cell which effectively\n",
    "relates to how many digits it can store in each \"cell\". Allocating space ahead of time\n",
    "allows computers to optimize storage and processing efficiency.\n",
    "\n",
    "### Text Data Type\n",
    "\n",
    "Text data type is known as Strings in Python, or Objects in Pandas. Strings can\n",
    "contain numbers and / or characters. For example, a string might be a word, a\n",
    "sentence, or several sentences. A Pandas object might also be a plot name like\n",
    "'plot1'. A string can also contain or consist of numbers. For instance, '1234'\n",
    "could be stored as a string. As could '10.23'. However **strings that contain\n",
    "numbers can not be used for mathematical operations**!\n",
    "\n",
    "Pandas and base Python use slightly different names for data types. More on this\n",
    "is in the table below:\n",
    "\n",
    "| Pandas Type | Native Python Type | Description |\n",
    "|-------------|--------------------|-------------|\n",
    "| object | string | The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n",
    "| int64  | int | Numeric characters. 64 refers to the memory allocated to hold this character. |\n",
    "| float64 | float | Numeric characters with decimals. If a column contains numbers and NaNs (see below), pandas will default to float64, in case your missing value has a decimal. |\n",
    "| datetime64, timedelta[ns] | N/A (but see the [datetime] module in Python's standard library) | Values meant to hold time data. Look into these for time series experiments. |\n",
    "\n",
    "[datetime]: http://doc.python.org/2/library/datetime.html\n",
    "\n",
    "\n",
    "### Checking the format of our data\n",
    "\n",
    "Now that we're armed with a basic understanding of numeric and text data\n",
    "types, let's explore the format of our survey data. Remember that we can check \n",
    "the type of an object like this:\n",
    "\n",
    "```python\n",
    "> type(surveys_df)\n",
    "        pandas.core.frame.DataFrame\n",
    "```\n",
    "\n",
    "Next, let's look at the structure of our surveys data. In pandas, we can check\n",
    "the type of one column in a DataFrame using the syntax\n",
    "`dataFrameName[column_name].dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type for survey column \"record_id\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type `int64` tells us that Python is storing each value within this column\n",
    "as a 64 bit integer. We can use the `dat.dtypes` command to view the data type\n",
    "for each column in a DataFrame (all at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the data types for all columns of surveys dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that most of the columns in our Survey data are of type `int64`. This means\n",
    "that they are 64 bit integers. But the weight column is a floating point value\n",
    "which means it contains decimals. The `species_id` and `sex` columns are objects which\n",
    "means they contain strings. \n",
    "\n",
    "We can modify the format of values within our data, if\n",
    "we want. For instance, we could convert the `record_id` field to floating point\n",
    "values.\n",
    "\n",
    "```python\n",
    "# Convert the record_id field from an integer to a float\n",
    "surveys_df['record_id'] = surveys_df['record_id'].astype('float64')\n",
    "surveys_df['record_id'].dtype\n",
    "```\n",
    "\n",
    "```python\n",
    "dtype('float64')\n",
    "```\n",
    "\n",
    "### Challenge: Changing Types\n",
    ">\n",
    "> Try converting the column `plot_id` to floats using\n",
    ">\n",
    "> ```\n",
    "> surveys_df.plot_id.astype(\"float\")\n",
    "> ```\n",
    ">\n",
    "> Next try converting `weight` to an integer. What goes wrong here? What is Pandas telling you?\n",
    "> We will talk about some solutions to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing type challenge below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Values - NaN\n",
    "\n",
    "What happened in the last challenge activity? Notice that this throws a value error:\n",
    "`ValueError: Cannot convert NA to integer`. If we look at the `weight` column in the surveys\n",
    "data we notice that there are NaN (**N**ot **a** **N**umber) values. **NaN** values are undefined\n",
    "values that cannot be represented mathematically. Pandas, for example, will read\n",
    "an empty cell in a CSV or Excel sheet as a NaN. NaNs have some desirable properties: if we\n",
    "were to average the `weight` column without replacing our NaNs, Python would know to skip\n",
    "over those cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean weight of sample\n",
    "surveys_df['weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing data values is always a challenge. It's sometimes hard to\n",
    "know why values are missing - was it because of a data entry error? Or data that\n",
    "someone was unable to collect? Should the value be 0? We need to know how\n",
    "missing values are represented in the dataset in order to make good decisions.\n",
    "If we're lucky, we have some metadata that will tell us more about how null\n",
    "values were handled.\n",
    "\n",
    "For instance, in some disciplines, like Remote Sensing, missing data values are\n",
    "often defined as -9999. Having a bunch of -9999 values in your data could really\n",
    "alter numeric calculations. Often in spreadsheets, cells are left empty where no\n",
    "data are available. Pandas will, by default, replace those missing values with\n",
    "NaN. However it is good practice to get in the habit of intentionally marking\n",
    "cells that have no data, with a no data value! That way there are no questions\n",
    "in the future when you (or someone else) explores your data.\n",
    "\n",
    "#### Where Are the NaN's?\n",
    "\n",
    "Let's explore the NaN values in our data a bit further. Using the tools we\n",
    "learned above, we can figure out how many rows contain NaN values for\n",
    "weight. We can also create a new subset from our data that only contains rows\n",
    "with weight values > 0 (i.e., select meaningful weight values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullweights = surveys_df[pd.isnull(surveys_df.weight)]\n",
    "positiveweights = surveys_df[surveys_df.weight> 0]\n",
    "\n",
    "print(len(nullweights))\n",
    "print(len(positiveweights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace all NaN values with zeroes using the `.fillna()` method (after\n",
    "making a copy of the data so we don't lose our work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a true copy of survey data\n",
    "df1 = \n",
    "\n",
    "# Fill NaN values in \"weight\" column with 0's using `.fillna()`\n",
    "df1['weight'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However NaN and 0 yield different analysis results. The mean value when NaN\n",
    "values are replaced with 0 is different from when NaN values are simply thrown\n",
    "out or ignored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean weight for 0-padded survey data\n",
    "df1['weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill NaN values with any value that we chose. The code below fills all\n",
    "NaN values with a mean for all weight values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['weight'] = surveys_df['weight'].fillna(surveys_df['weight'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also chose to create a subset of our data, only keeping rows that do\n",
    "not contain NaN values.\n",
    "\n",
    "The point is to make conscious decisions about how to manage missing data. This\n",
    "is where we think about how our data will be used and how these values will\n",
    "impact the scientific conclusions made from the data.\n",
    "\n",
    "Python gives us all of the tools that we need to account for these issues. We\n",
    "just need to be cautious about how the decisions that we make impact scientific\n",
    "results.\n",
    "\n",
    "### Challenge - Counting\n",
    "> Count the number of missing values per column. Hint: The method .count() gives you\n",
    "> the number of non-NA observations per column. Try looking to the .isnull() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting challenge code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV\n",
    "\n",
    "We've learned about using manipulating data to get desired outputs. But we've also discussed\n",
    "keeping data that has been manipulated separate from our raw data. Something we might be interested\n",
    "in doing is working with only the columns that have full data. First, let's reload the data so\n",
    "we're not mixing up all of our previous manipulations.\n",
    "\n",
    "```python\n",
    "surveys_df = pd.read_csv(\"data/surveys.csv\")\n",
    "```\n",
    "\n",
    "Next, let's drop all the rows that contain missing values. We will use the command `dropna`.\n",
    "By default, dropna removes rows that contain missing data for even just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN's from survey data, return to new dataframe\n",
    "df_na = surveys_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now type `df_na`, you should observe that the resulting DataFrame has 30676 rows\n",
    "and 9 columns, much smaller than the 35549 row original.\n",
    "\n",
    "We can now use the `to_csv` command to do export a DataFrame in CSV format. Note that the code\n",
    "below will by default save the data into the current working directory. We can\n",
    "save it to a different folder by adding the foldername and a slash before the filename:\n",
    "`df.to_csv('foldername/out.csv')`. We use 'index=False' so that\n",
    "pandas doesn't include the index number for each line.\n",
    "\n",
    "```python\n",
    "# Write DataFrame to CSV\n",
    "df_na.to_csv('data_output/surveys_complete.csv', index=False)\n",
    "```\n",
    "\n",
    "## Recap\n",
    "\n",
    "What we've learned:\n",
    "\n",
    "+ How to explore the data types of columns within a DataFrame\n",
    "+ How to change the data type\n",
    "+ What NaN values are, how they might be represented, and what this means for your work\n",
    "+ How to replace NaN values, if desired\n",
    "+ How to use `to_csv` to write manipulated data to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
